#!/usr/bin/env python3

import argparse
import ROOT
import os
import pdb # python debugger might be helpful (see https://docs.python.org/3/library/pdb.html)

from python.utils import load_input_csv, load_histogram

ROOT.gROOT.SetBatch(True) # disable root prompts

parser = argparse.ArgumentParser()
parser.add_argument("-b", "--beginRun", help="First run to analyze [%(default)s]", type=int, default=272007)
parser.add_argument("-e", "--endRun", help="Analyze stops when comes to this run [%(default)s]", type=int, default=1000000)
parser.add_argument("-i", "--dirDQM", help="Directory to the input root files from the DQM Offline module", required=True)
parser.add_argument("--byLsCSV", help="ByLs csv input generated by brilcalc", default="default")
parser.add_argument("-o", "--dirOut", help="where to store the output files", default="./")
args = parser.parse_args()

print("Initialial settings")

dirDQM = args.dirDQM
dirOut = args.dirOut
beginRun = args.beginRun
endRun = args.endRun
byLsCSV = args.byLsCSV # contains the reference luminosity

etaRegion = "B" # define eta region. Currently supported are "B" (Barrel) and "I" (Inclusive)

nBinsMass = 50  # number of bins in histograms to fit
massLo = 66     # lower boundary for fit range
massHi = 116    # upper boundary for fit range

maximumLS = 2500        # maximum luminosity block number that is stored in the DQM histograms
minLSperRun = 20        # only consider runs with at least 20 luminosity blocks
LumiPerMeasurement = 10 # minimum amount of luminosity required to perform one measurement
ptCut = 27              # pT cut on muons, only for labeling
etaCut = 2.4 # |eta| cut on muons, only for labeling            

print(f"Load the ByLS csv file {byLsCSV} with information of the reference luminosity")
byLS_data = load_input_csv(byLsCSV)

if not os.path.isdir(dirOut):
    print(f"create output directory {dirOut}")
    os.mkdir(dirOut)

dirMacros = os.path.dirname(os.path.realpath(__file__)) + "/calculateDataEfficiency.C"
print(f"Load root macros from {dirMacros} ...")
ROOT.gROOT.LoadMacro(dirMacros)
ROOT.set_massRange(massLo, massHi, nBinsMass)
ROOT.set_ptCut(ptCut)
ROOT.set_etaCut(etaCut)

# loop over all runs to be fit
print("Looping over runs ...")
for run, byLS_run in byLS_data.groupby('run'):

    if run < int(args.beginRun) or run >= int(args.endRun):
        continue
    
    fill = byLS_run.drop_duplicates('fill')['fill'].values[0]
    LSlist = byLS_run.query('ls <= {0}'.format(maximumLS))['ls'].values.tolist()

    # Consider only runs with a minimum number of LS
    if len(LSlist) <= minLSperRun:
        print(f"Skip run {run} since it only has {len(LSlist)} LS".format(run, len(LSlist)))
        continue
    
    print(f"Now at run {run}")
    fileName = dirDQM+f"/DQM_V0001_R000{run}__SingleMuon__Run2018D-12Nov2019_UL2018-v4__DQMIO.root"
    
    if not os.path.isfile(fileName):
        print("WARNING: no DQM file found! continue with next run")
        continue

    print("Looping over measurements ...")
    m = -1
    while len(LSlist) > 0:  # begin next measurement "m"
        m += 1
        print(f"Now at measurement {m}")
        
        # merge data to one measuement if remaining luminosity is too less for two measuements
        mergeMeasurements = sum(byLS_run.loc[byLS_run['ls'].isin(LSlist)]['recorded(/pb)'].values) < 1.5 * LumiPerMeasurement

        recLumi = 0
        # produce goodLSlist with ls that are used for one measurement
        goodLSlist = []
        while len(LSlist) > 0:
            goodLSlist.append(LSlist[0])
            recLumi += (byLS_run[byLS_run['ls'] == LSlist[0]]['recorded(/pb)'].values)[0]
            del LSlist[0]
            # if we have enough collected lumisections
            if not mergeMeasurements and recLumi >= LumiPerMeasurement:# or len(goodLSlist) >= LSperMeasurement):
                break
        
        # create datafram byLS for measurement
        byLS_m = byLS_run.loc[byLS_run['ls'].isin(goodLSlist)]
        
        # get histograms from good lumisections
        def load(name_):
            return load_histogram(name_, fileName, goodLSlist, run=run, 
                MassBin=nBinsMass, MassMin=massLo, MassMax=massHi, 
                prefix=f"DQMData/Run {run}/ZCounting/Run summary/Histograms/", 
                suffix="new")

        print("Load histograms ...")
        h_mass_yield_Z = load("h_mass_yield_Z")
        
        h_HLT_pass = load("h_mass_HLT_pass_central")
        h_HLT_fail = load("h_mass_HLT_fail_central")

        h_SIT_pass = load("h_mass_SIT_pass_central")
        h_SIT_fail = load("h_mass_SIT_fail_central")

        h_Glo_pass = load("h_mass_Glo_pass_central")
        h_Glo_fail = load("h_mass_Glo_fail_central")

        if etaRegion == "I":
            h_HLT_pass.Add(load("h_mass_HLT_pass_forward"))
            h_HLT_fail.Add(load("h_mass_HLT_fail_forward"))

            h_SIT_pass.Add(load("h_mass_SIT_pass_forward"))
            h_SIT_fail.Add(load("h_mass_SIT_fail_forward"))

            h_Glo_pass.Add(load("h_mass_Glo_pass_forward"))
            h_Glo_fail.Add(load("h_mass_Glo_fail_forward"))

        if h_HLT_pass.Integral() == 0:
            print("WARNING: no Z candidates found! continue with next run")
            continue
        
        dirOutSub = f"{dirOut}/Run{run}"
        if not os.path.isdir(dirOutSub):
            print(f"create output directory {dirOutSub}")
            os.mkdir(dirOutSub)
            
        ROOT.set_output(dirOutSub)
        ROOT.set_luminosity(recLumi)

        print("Perform fits to calculate efficiencies")
        ROOT.calculateDataEfficiency(
            h_HLT_pass, h_HLT_fail,
            m, "HLT", etaRegion, 1, 6, 1, 6)

        ROOT.calculateDataEfficiency(
            h_SIT_pass, h_SIT_fail,
            m, "SIT", etaRegion, 1, 6, 1, 6)

        ROOT.calculateDataEfficiency(
            h_Glo_pass, h_Glo_fail,
            m, "Glo", etaRegion, 1, 6, 1, 6)            

        print("Load fit results ...")
        
        def load_from_workspace(type_eff):
            filename_eff = f"{dirOutSub}/workspace_{type_eff}_{etaRegion}_{m}.root"
            if not os.path.isfile(filename_eff):
                print(f"WARNING: fit result {filename_eff} does not exist! exit")
                exit()
            tfile_eff = ROOT.TFile(filename_eff,"READ")
            workspace = tfile_eff.Get("workspace")
            eff = workspace.var("eff").getVal()
            return eff

        effHLT = load_from_workspace("HLT")
        effSIT = load_from_workspace("SIT")
        effGlo = load_from_workspace("Glo")
        
        # trigger efficiency that onmly one or both muons pass the trigger
        effTrigger = (1 - (1-effHLT)**2 )
        
        # reconstructed number of Zs, do not perform fit but assume 1% background
        recoZ = h_mass_yield_Z.Integral() * 0.99
        
        # delivered number of Zs given by efficiency corrected number of reconstructed Zs
        delZ = recoZ / (effTrigger * effSIT**2 * effGlo**2)

        print(f"Delivered number of Zs = {delZ}")
        
        # for testing exit after two measurements
        if m >= 1:
            exit()
