#!/usr/bin/env python3

from python import logging
from python import common


def zmonitoring(
    dirDQM,
    dirOut,
    byLsCSV,
    mcCorrections,
    sigModel,
    bkgModel,
    ptCut,
    etaCut,
    mass,
    LumiPerMeasurement,
    mode,
    test,
    runlist = None,
    beginRun=0,
    endRun=400000,
    longQueue=False # submit on the long queue
):
    import os
    import pandas as pd
    import glob
    import json

    if runlist == None:
        log.info("create runlist from byLsCSV file")
        with open(byLsCSV) as file:
            byLS_lines = file.readlines()
        byLS_data = pd.read_csv(
            byLsCSV, sep=',', low_memory=False,
            skiprows=lambda x: byLS_lines[x].startswith('#') and not byLS_lines[x].startswith('#run'))

        minLS = 20   # Consider only runs with more than least 5 LS
        # number of lumisections per Run
        nLS = byLS_data.pivot_table(columns=['#run:fill'], aggfunc='size')

        log.info("sort out {0} runs with less than {1} LS".format(sum(nLS.values <= minLS), minLS))
        runlist = byLS_data['#run:fill'].str.split(':', expand=True)[0].drop_duplicates()
        runlist = runlist[nLS.values > minLS].tolist()

    cmsswbase = os.environ['CMSSW_BASE']
    if not cmsswbase:
        log.error("please set cmsenv")
        exit()

    cs_file = open("cs_tmp.sub", "w")

    cs_file.write("executable  = runZCountingOnBatch.sh \n")
    cs_file.write("output      = condor/$(ClusterId).$(ProcId).out \n")
    cs_file.write("error       = condor/$(ClusterId).$(ProcId).err \n")
    cs_file.write("log         = condor/$(ClusterId).$(ProcId).log \n")
    #cs_file.write("+JobFlavour =\"testmatch\" \n") # only works at lxplus
    # cs_file.write("+RequestRuntime = 43200 \n")  # only works at naf(desy) 43200s = 12h
    # cs_file.write("RequestMemory = 19999 \n")
    if longQueue:
        # long queue
        cs_file.write("+RequestRuntime = 43200 \n")  # only works at naf(desy) 43200s = 12h
        cs_file.write("RequestMemory = 19999 \n") 
    else:
        # short queue: with memory < 2GB -> request 1999MB and time < 3h -> request 10799s
        cs_file.write("+RequestRuntime = 10799 \n")  # only works at naf(desy) 43200s = 12h
        cs_file.write("RequestMemory = 1999 \n") 

    log.info(f"Have {len(runlist)} runs")
    
    njobs=0
    runs = []
    for run in runlist:
        if int(run) < beginRun or int(run) > endRun:
            continue
        if len(glob.glob(dirDQM+"/000*/*{0}*.root".format(run))) == 0:
        #if len(glob.glob(dirDQM+"/*Muon_{0}*.root".format(run))) == 0:
            continue
        runs.append(run)
        cs_file.write("arguments  = {0} {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} {12} {13} {14}\n".format(
            run,
            cmsswbase,
            dirDQM,
            byLsCSV,
            dirOut,
            mcCorrections,
            sigModel,
            bkgModel,
            ptCut,
            etaCut,
            mass[0],
            mass[1],
            mass[2],
            LumiPerMeasurement,
            mode
    	))
        njobs += 1

        cs_file.write("queue\n")
    cs_file.close()
    if test:
        log.info("Execute command to run jobs: ")
        log.info("condor_submit cs_tmp.sub")
        exit()
    else:
        out = os.popen("condor_submit cs_tmp.sub --verbose").read()
        log.info(out)
    #os.system("rm cs_tmp.sub")
    out = out.split("\n")[-2].split(" ")
    clusterId = int(out[-1][:-1])

    # create jobinformation
    ji = {
        'process' : 'zmonitoring',
        'dirDQM': dirDQM,
        'dirOut': dirOut,
        'byLsCSV': byLsCSV,
        'mcCorrections': mcCorrections,
        'sigModel': sigModel,
        'bkgModel': bkgModel,
        'mass_lo': mass[0],
        'mass_hi': mass[1],
        'mass_bins': mass[2],
        'luminosity': LumiPerMeasurement,
        'mode': mode,
        'ptCut': ptCut,
        'etaCut': etaCut,
        'runs': runs,
        'njobs': njobs,
        'clusterId': clusterId
    }
    # write jobinformation
    if not os.path.isdir(dirOut):
        os.mkdir(dirOut)
    with open(dirOut+'/jobinfo.json'.format(clusterId), 'w') as f:
        json.dump(ji, f, indent=4, separators=(',', ': '))

def check(projectdir, resubmit=False, collect=False, longQueue=False):
    import os
    import json

    if collect:
        from python.utils import writeSummaryCSV     
        writeSummaryCSV(projectdir+"/csvFiles/", writeByLS=False)

    with open(projectdir+'/jobinfo.json', 'r') as f:
        ji = json.load(f)

    if resubmit:
        from subprocess import call
    else:
        def call(name, **opts):
            print(name)

    unfinished_jobs = []
    for ijob in range(ji['njobs']):
        outfilename = "condor/{0}.{1}.err".format(ji['clusterId'], ijob)
        if not os.path.isfile(outfilename) or os.stat(outfilename).st_size == 0: #file does not exist or is empty?
            unfinished_jobs.append(ijob)
            continue
        with open(outfilename, "r") as f:
            lastline = f.readlines()[-1]
        if lastline != "INFO:ZCounting.py:Done\n":
            unfinished_jobs.append(ijob)
    if len(unfinished_jobs) == 0:
        log.info("all jobs done!")
    else:
        log.info("unfinished jobs: {0}".format(unfinished_jobs))
        if resubmit:
            log.info("resubmit unfinished jobs")
            faildir = projectdir+'/failed'+str(ji['clusterId'])
            if not os.path.isdir(faildir):
                os.mkdir(faildir)
                os.mkdir(faildir+'/csvFiles')
            os.system("mv {0}/jobinfo.json {0}/jobinfo{1}.json".format(projectdir, ji['clusterId']))

            if ji['process'] == 'zmonitoring':
                for ijob in unfinished_jobs:

                    runDir = "{0}/Run{1}".format(projectdir, ji['runs'][ijob])
                    if os.path.isdir(runDir):
                        os.system("mv {0} {1}/".format(runDir, faildir))

                    csvFile = "{0}/csvFiles/csvfile{1}.csv".format(projectdir, ji['runs'][ijob])
                    if os.path.isfile(csvFile):
                        os.system("mv {0} {1}/csvFiles/".format(csvFile, faildir))

                zmonitoring(
                    ji['dirDQM'], ji['dirOut'], ji['byLsCSV'], ji['mcCorrections'], ji['sigModel'], ji['bkgModel'],
                    ji['ptCut'], ji['etaCut'], (ji['mass_lo'], ji['mass_hi'], ji['mass_bins']), 
                    ji['luminosity'], ji['mode'], False,
                    runlist=[ji['runs'][i] for i in unfinished_jobs],
                    longQueue=longQueue)

# ------------------------------------------------------------------------------
# parse command line arguments
if __name__ == '__main__':
    # setup argument parser
    import pdb
    
    parser = common.parser()
    subparsers = parser.add_subparsers(dest='subparser')

    # command line arguments: zmonitoring
    parserA = subparsers.add_parser(
        'zmonitoring',
        help='submit ZMonitoring jobs to HTCondor'
    )
    parserA = common.parser_zharvest(parserA)
    parserA.add_argument(
        '-t', '--test', default=False, action="store_true",
        help='test without submitting, just create the submit script'
    )
    parserA.add_argument(
        '--longQueue', default=False, action="store_true",
        help='submit on the long queue'
    )
    # command line arguments: check
    parserC = subparsers.add_parser(
        'check',
        help='check ZMonitoring jobs that have been submitted to HTCondor'
    )
    parserC.add_argument(
        '-i', '--project', type=str, required=True,
        help='specify directory to jobinfo.json file'
    )
    parserC.add_argument(
        '--resubmit', default=False, action="store_true",
        help='to resubmit failed jobs'
    )
    parserC.add_argument(
        '--collect', default=False, action="store_true",
        help='Merge result csv files of finished jobs'
    )
    parserC.add_argument(
        '--longQueue', default=False, action="store_true",
        help='resubmit on the long queue'
    )

    # parse arguments and call subparser
    args = parser.parse_args()

    log = setup_logger(__file__, args.verbose)

    if args.subparser == 'zmonitoring':
        zmonitoring(
            args.inputDQM,
            args.output,
            args.byLsCSV,
            args.mcCorrections,
            args.sigModel,
            args.bkgModel,
            args.ptCut,
            args.etaCut,
            args.mass,
            args.LumiPerMeasurement,
            args.mode,
            args.test,
            beginRun=args.beginRun,
            endRun=args.endRun,
            longQueue=args.longQueue)
    if args.subparser == 'check':
        check(
            args.project, 
            args.resubmit, 
            args.collect,
            longQueue=args.longQueue)
     
    
