#!/usr/bin/env python

def zmonitoring(
    dirDQM,
    dirOut,
    byLsCSV,
    mcCorrections,
    sigTemplates,
    bkgTemplates,
    ptCut,
    mass,
    LumiPerMeasurement,
    test,
    runlist = None,
    beginRun=0,
    endRun=400000
):
    import os
    import pandas as pd
    import glob
    import subprocess
    import json

    if runlist == None:
        print("create runlist from byLsCSV file")
        with open(byLsCSV) as file:
            byLS_lines = file.readlines()
        byLS_data = pd.read_csv(
            byLsCSV, sep=',', low_memory=False,
            skiprows=lambda x: byLS_lines[x].startswith('#') and not byLS_lines[x].startswith('#run'))

        minLS = 5   # Consider only runs with more than least 5 LS
        # number of lumisections per Run
        nLS = byLS_data.pivot_table(columns=['#run:fill'], aggfunc='size')

        print("sort out {0} runs with less than {1} LS".format(sum(nLS.values <= minLS), minLS))
        runlist = byLS_data['#run:fill'].str.split(':', expand=True)[0].drop_duplicates()
        runlist = runlist[nLS.values > minLS].tolist()

    cmsswbase = os.environ['CMSSW_BASE']
    if not cmsswbase:
        print("please set cmsenv")
        exit()

    cs_file = open("cs_tmp.sub", "w")

    cs_file.write("executable  = runZCountingOnBatch.sh \n")
    cs_file.write("output      = condor/$(ClusterId).$(ProcId).out \n")
    cs_file.write("error       = condor/$(ClusterId).$(ProcId).err \n")
    cs_file.write("log         = condor/$(ClusterId).$(ProcId).log \n")
    #cs_file.write("+JobFlavour =\"testmatch\" \n") # only works at lxplus
    #cs_file.write("+RequestRuntime = 43200 \n")  # only works at naf(desy) 43200s = 12h
    #cs_file.write("RequestMemory = 19999 \n")

    runs = []
    for run in runlist:
        if int(run) < beginRun or int(run) > endRun:
            continue
        if len(glob.glob(dirDQM+"/000*/*{0}*.root".format(run))) == 0:
            continue
        runs.append(run)
        cs_file.write("arguments  = {0} {1} {2} {3} {4} {5} {6} {7} {8} {9} {10} {11} {12}\n".format(
            run,
            cmsswbase,
            dirDQM,
            byLsCSV,
            dirOut,
            mcCorrections,
            sigTemplates,
            bkgTemplates,
            ptCut,
            mass[0],
            mass[1],
            mass[2],
            LumiPerMeasurement
    	))

        cs_file.write("queue\n")
    cs_file.close()
    if test:
        print("Execute command to run jobs: ")
        print("condor_submit cs_tmp.sub")
        exit()
    else:
        out = os.popen("condor_submit cs_tmp.sub").read()
        print(out)
    #os.system("rm cs_tmp.sub")

    out = out.split("\n")[-2].split(" ")
    njobs = int(out[0])
    clusterId = int(out[-1][:-1])

    # create jobinformation
    ji = {
        'process' : 'zmonitoring',
        'dirDQM': dirDQM,
        'dirOut': dirOut,
        'byLsCSV': byLsCSV,
        'mcCorrections': mcCorrections,
        'sigTemplates': sigTemplates,
        'bkgTemplates': bkgTemplates,
        'mass_lo': mass[0],
        'mass_hi': mass[1],
        'mass_bins': mass[2],
        'luminosity': LumiPerMeasurement,
        'ptCut': ptCut,
        'runs': runs,
        'njobs': njobs,
        'clusterId': clusterId
    }
    # write jobinformation
    if not os.path.isdir(dirOut):
        os.mkdir(dirOut)
    with open(dirOut+'/jobinfo.json'.format(clusterId), 'w') as f:
        json.dump(ji, f, indent=4, separators=(',', ': '))

def check(projectdir, resubmit=False, collect=False):
    import os
    import json

    if collect:
        from python.utils import writeSummaryCSV     
        writeSummaryCSV(projectdir+"/csvFiles/", writeByLS=True)

    with open(projectdir+'/jobinfo.json', 'r') as f:
        ji = json.load(f)

    if resubmit:
        from subprocess import call
    else:
        def call(name, **opts):
            print(name)

    unfinished_jobs = []
    for ijob in range(ji['njobs']):
        outfilename = "condor/{0}.{1}.err".format(ji['clusterId'], ijob)
        if not os.path.isfile(outfilename) or os.stat(outfilename).st_size == 0: #file does not exist or is empty?
            unfinished_jobs.append(ijob)
            continue
        with open(outfilename, "r") as f:
            lastline = f.readlines()[-1]
        if lastline != "INFO:  ===Done\n":
            unfinished_jobs.append(ijob)
    if len(unfinished_jobs) == 0:
        print("all jobs done!")
    else:
        print("unfinished jobs: {0}".format(unfinished_jobs))
        if resubmit:
            print("resubmit unfinished jobs")
            faildir = projectdir+'/failed'+str(ji['clusterId'])
            if not os.path.isdir(faildir):
                os.mkdir(faildir)
                os.mkdir(faildir+'/csvFiles')
            os.system("mv {0}/jobinfo.json {0}/jobinfo{1}.json".format(projectdir, ji['clusterId']))

            if ji['process'] == 'zmonitoring':
                for ijob in unfinished_jobs:

                    runDir = "{0}/Run{1}".format(projectdir, ji['runs'][ijob])
                    if os.path.isdir(runDir):
                        os.system("mv {0} {1}/".format(runDir, faildir))

                    csvFile = "{0}/csvFiles/csvfile{1}.csv".format(projectdir, ji['runs'][ijob])
                    if os.path.isfile(csvFile):
                        os.system("mv {0} {1}/csvFiles/".format(csvFile, faildir))

                zmonitoring(ji['dirDQM'], ji['dirOut'], ji['byLsCSV'], ji['mcCorrections'], ji['sigTemplates'], ji['bkgTemplates'], ji['ptCut'],
                    (ji['mass_lo'], ji['mass_hi'], ji['mass_bins']), ji['luminosity'], False,
                    runlist=[ji['runs'][i] for i in unfinished_jobs])

# ------------------------------------------------------------------------------
# parse command line arguments
if __name__ == '__main__':
    # setup argument parser
    import argparse, pdb
    parser = argparse.ArgumentParser(prog='./submit')
    subparsers = parser.add_subparsers(dest='subparser')

    # command line arguments: zmonitoring
    parserA = subparsers.add_parser(
        'zmonitoring',
        help='submit ZMonitoring jobs to HTCondor'
    )
    parserA.add_argument(
        '-i', '--inputDQM', type=str, default="default",
        help='specify directory to input histogram .root files'
    )
    parserA.add_argument(
        "-b", "--beginRun", default=272007, type=int,
        help="first run to analyze [%(default)s]"
    )
    parserA.add_argument(
        "-e", "--endRun", default=1000000, type=int,
        help="analyze stops when comes to this run [%(default)s]"
    )
    parserA.add_argument(
        '--mcCorrections', default="default", type=str,
        help='specify .json file with MC corrections for muon correlations'
    )
    parserA.add_argument(
        '--sigTemplates', default="default", type=str,
        help='specify if MC template is unsigned for signal shapes'
    )
    parserA.add_argument(
        '--bkgTemplates', default="None", type=str,
        help='specify if MC template is unsigned for background shapes'
    )
    parserA.add_argument(
        '--LumiPerMeasurement', default=20, type=float,
        help='specify amount of luminosity per measurement in pb-1'
    )
    parserA.add_argument(
        '--mass', nargs=3, metavar=('LOW', 'HIGH', 'NBINS'), default=(70, 250, 360),
        help='specify mass range for tag and probe muon pairs'
    )
    parserA.add_argument(
        '--byLsCSV', default="default", type=str,
        help='specify byLsCSV to select specific lumi sections'
    )
    parserA.add_argument(
        '--ptCut', type=float, default=30.,
        help='specify lower pt cut on tag and probe muons'
    )
    parserA.add_argument(
        '-o', '--output', default='./',
        help='specify output dir'
    )
    parserA.add_argument(
        '-t', '--test', default=False, action="store_true",
        help='test without submitting, just create the submit script'
    )

    # command line arguments: check
    parserC = subparsers.add_parser(
        'check',
        help='check ZMonitoring jobs that have been submitted to HTCondor'
    )
    parserC.add_argument(
        '-i', '--project', type=str, required=True,
        help='specify directory to jobinfo.json file'
    )
    parserC.add_argument(
        '--resubmit', default=False, action="store_true",
        help='to resubmit failed jobs'
    )
    parserC.add_argument(
        '--collect', default=False, action="store_true",
        help='Merge result csv files of finished jobs'
    )


    # parse arguments and call subparser
    args = parser.parse_args()
    if args.subparser == 'zmonitoring':
        zmonitoring(
            args.inputDQM,
            args.output,
            args.byLsCSV,
            args.mcCorrections,
            args.sigTemplates,
            args.bkgTemplates,
            args.ptCut,
            args.mass,
            args.LumiPerMeasurement,
            args.test,
            beginRun=args.beginRun,
            endRun=args.endRun)
    if args.subparser == 'check':
        check(args.project, args.resubmit, args.collect)
     
    
